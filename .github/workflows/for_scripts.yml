name: Generate MikroTik RSC Files for scripts
on:
  schedule:
    - cron: "10 0 * * *" # 00:10 UTC
  workflow_dispatch:
concurrency:
  group: for-scripts-main
  cancel-in-progress: true
permissions:
  contents: write
env:
  MAX_ENTRIES_PER_FILE: 150
  GROUP: "anime,art,casino,education,games,messengers,music,news,porn,shop,socials,tools,torrent,video"
  SITE: ""
  GROUP_URL_TEMPLATE: https://iplist.opencck.org/?format=json&data=domains&wildcard=1&group={group}
  SITE_URL_TEMPLATE: https://iplist.opencck.org/?format=json&data=domains&wildcard=1&site={site}
jobs:
  generate-rsc:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout your repo
        uses: actions/checkout@v4

      - name: Clean previous generated scripts
        run: |
          set -eu
          git rm -r --ignore-unmatch -- for_scripts/*.rsc for_scripts/index.* || true
          mkdir -p for_scripts

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Process groups and sites form iplist.opencck.org
        run: |
          set -e
          IFS=',' read -ra group_array <<< "${{ env.GROUP }}"
          IFS=',' read -ra site_array <<< "${{ env.SITE }}"
          GROUP_URL_TEMPLATE="${{ env.GROUP_URL_TEMPLATE }}"
          SITE_URL_TEMPLATE="${{ env.SITE_URL_TEMPLATE }}"
          MAX_ENTRIES_PER_FILE="${{ env.MAX_ENTRIES_PER_FILE }}"

          mkdir -p for_scripts

          # Process groups
          for group in "${group_array[@]}"; do
              group=$(echo "$group" | xargs)
              echo "Processing group: $group"
              json_url="${GROUP_URL_TEMPLATE//\{group\}/$group}"
              
              if ! curl -s -f "$json_url" > "input_$group.json"; then
                  echo "Failed to fetch JSON for group $group, skipping..."
                  continue
              fi

              # Initialize array for all suffixes in the group
              group_suffixes=()

              # Get resource names (keys) from JSON
              resources=$(jq -r 'keys[]' "input_$group.json" | sort -u)

              # Process each resource in the group
              while IFS= read -r resource; do
                  # Extract base resource name without TLD
                  base_resource=$(echo "$resource" | sed -E 's/\.[a-zA-Z]+$//')
                  echo "Processing resource: $base_resource (from $resource)"
                  
                  # Get domains for the resource (all treated as suffixes with match-subdomain=yes)
                  suffixes=$(jq -r --arg resource "$resource" '.[$resource][]' "input_$group.json" | sort -u | grep -v '^$' || true)

                  # Add suffixes to group_suffixes for combined group file
                  if [ -n "$suffixes" ]; then
                      while IFS= read -r suffix; do
                          group_suffixes+=("$suffix")
                      done <<< "$suffixes"
                  fi

                  # Combine suffixes into entries for individual resource, only if non-empty
                  all_entries=()
                  if [ -n "$suffixes" ]; then
                      while IFS= read -r suffix; do
                          all_entries+=("suffix:$suffix")
                      done <<< "$suffixes"
                  fi

                  # Skip if no valid entries
                  entry_count=${#all_entries[@]}
                  if [ $entry_count -eq 0 ]; then
                      echo "No valid entries for $base_resource, skipping..."
                      continue
                  fi

                  # Check if entries fit in one file
                  if [ $entry_count -le $MAX_ENTRIES_PER_FILE ]; then
                      output_file="for_scripts/${base_resource}.rsc"
                      echo ":global AddressList" > "$output_file"
                      echo ":global ForwardTo" >> "$output_file"
                      echo "/ip dns static" >> "$output_file"
                      for entry in "${all_entries[@]}"; do
                          type=$(echo "$entry" | cut -d':' -f1)
                          value=$(echo "$entry" | cut -d':' -f2-)
                          if [ "$type" = "suffix" ]; then
                              echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$base_resource\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                          fi
                      done
                  else
                      # Split into multiple files
                      part=1
                      entry_index=0
                      while [ $entry_index -lt $entry_count ]; do
                          output_file="for_scripts/${base_resource}_part${part}.rsc"
                          echo ":global AddressList" > "$output_file"
                          echo ":global ForwardTo" >> "$output_file"
                          echo "/ip dns static" >> "$output_file"
                          for ((i=0; i<MAX_ENTRIES_PER_FILE && entry_index<entry_count; i++, entry_index++)); do
                              entry=${all_entries[$entry_index]}
                              type=$(echo "$entry" | cut -d':' -f1)
                              value=$(echo "$entry" | cut -d':' -f2-)
                              if [ "$type" = "suffix" ]; then
                                  echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$base_resource\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                              fi
                          done
                          part=$((part + 1))
                      done
                  fi
              done <<< "$resources"

              # Create combined group file
              if [ ${#group_suffixes[@]} -gt 0 ]; then
                  echo "Creating combined file for group: $group"
                  all_entries=()
                  # Sort and deduplicate group_suffixes
                  sorted_suffixes=$(printf '%s\n' "${group_suffixes[@]}" | sort -u | grep -v '^$' || true)
                  if [ -n "$sorted_suffixes" ]; then
                      while IFS= read -r suffix; do
                          all_entries+=("suffix:$suffix")
                      done <<< "$sorted_suffixes"
                  fi

                  entry_count=${#all_entries[@]}
                  if [ $entry_count -eq 0 ]; then
                      echo "No valid entries for group $group, skipping combined file..."
                  else
                      if [ $entry_count -le $MAX_ENTRIES_PER_FILE ]; then
                          output_file="for_scripts/$group.rsc"
                          echo ":global AddressList" > "$output_file"
                          echo ":global ForwardTo" >> "$output_file"
                          echo "/ip dns static" >> "$output_file"
                          for entry in "${all_entries[@]}"; do
                              type=$(echo "$entry" | cut -d':' -f1)
                              value=$(echo "$entry" | cut -d':' -f2-)
                              if [ "$type" = "suffix" ]; then
                                  echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:group:$group\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                              fi
                          done
                      else
                          # Split into multiple files
                          part=1
                          entry_index=0
                          while [ $entry_index -lt $entry_count ]; do
                              output_file="for_scripts/${group}_part${part}.rsc"
                              echo ":global AddressList" > "$output_file"
                              echo ":global ForwardTo" >> "$output_file"
                              echo "/ip dns static" >> "$output_file"
                              for ((i=0; i<MAX_ENTRIES_PER_FILE && entry_index<entry_count; i++, entry_index++)); do
                                  entry=${all_entries[$entry_index]}
                                  type=$(echo "$entry" | cut -d':' -f1)
                                  value=$(echo "$entry" | cut -d':' -f2-)
                                  if [ "$type" = "suffix" ]; then
                                      echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:group:$group\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                                  fi
                              done
                              part=$((part + 1))
                          done
                      fi
                  fi
              else
                  echo "No valid suffixes for group $group, skipping combined file..."
              fi
          done

          # Process individual sites
          for site in "${site_array[@]}"; do
              site=$(echo "$site" | xargs)
              echo "Processing site: $site"
              json_url="${SITE_URL_TEMPLATE//\{site\}/$site}"
              
              if ! curl -s -f "$json_url" > "input_$site.json"; then
                  echo "Failed to fetch JSON for site $site, skipping..."
                  continue
              fi

              # Extract base resource name without TLD
              base_resource=$(echo "$site" | sed -E 's/\.[a-zA-Z]+$//')
              echo "Processing resource: $base_resource (from $site)"

              # Get domains for the site (all treated as suffixes with match-subdomain=yes)
              suffixes=$(jq -r --arg site "$site" '.[$site][]' "input_$site.json" | sort -u | grep -v '^$' || true)

              # Combine suffixes into entries, only if non-empty
              all_entries=()
              if [ -n "$suffixes" ]; then
                  while IFS= read -r suffix; do
                      all_entries+=("suffix:$suffix")
                  done <<< "$suffixes"
              fi

              # Skip if no valid entries
              entry_count=${#all_entries[@]}
              if [ $entry_count -eq 0 ]; then
                  echo "No valid entries for $base_resource, skipping..."
                  continue
              fi

              # Check if entries fit in one file
              if [ $entry_count -le $MAX_ENTRIES_PER_FILE ]; then
                  output_file="for_scripts/${base_resource}.rsc"
                  echo ":global AddressList" > "$output_file"
                  echo ":global ForwardTo" >> "$output_file"
                  echo "/ip dns static" >> "$output_file"
                  for entry in "${all_entries[@]}"; do
                      type=$(echo "$entry" | cut -d':' -f1)
                      value=$(echo "$entry" | cut -d':' -f2-)
                      if [ "$type" = "suffix" ]; then
                          echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$base_resource\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                      fi
                  done
              else
                  # Split into multiple files
                  part=1
                  entry_index=0
                  while [ $entry_index -lt $entry_count ]; do
                      output_file="for_scripts/${base_resource}_part${part}.rsc"
                      echo ":global AddressList" > "$output_file"
                      echo ":global ForwardTo" >> "$output_file"
                      echo "/ip dns static" >> "$output_file"
                      for ((i=0; i<MAX_ENTRIES_PER_FILE && entry_index<entry_count; i++, entry_index++)); do
                          entry=${all_entries[$entry_index]}
                          type=$(echo "$entry" | cut -d':' -f1)
                          value=$(echo "$entry" | cut -d':' -f2-)
                          if [ "$type" = "suffix" ]; then
                              echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$base_resource\" match-subdomain=yes type=FWD name=\"$value\" }" >> "$output_file"
                          fi
                      done
                      part=$((part + 1))
                  done
              fi
          done

      - name: Clone MetaCubeX/meta-rules-dat (branch-sing)
        run: |
          git clone --depth 1 --branch sing https://github.com/MetaCubeX/meta-rules-dat.git
          echo "Cloned MetaCubeX/meta-rules-dat (sing)"

      - name: Find all geosite JSON files
        id: find_files
        run: |
          cd meta-rules-dat
          if [ ! -d "geo/geosite" ]; then
            echo "Error: Directory geo/geosite not found!"
            echo "Available dirs:"
            find . -type d -name "geo*" || true
            exit 1
          fi
          find "geo/geosite" -name "*.json" | sed 's|.*/||' | sort > ../geosite_files.txt
          FILE_COUNT=$(wc -l < ../geosite_files.txt)
          echo "Found $FILE_COUNT JSON files in geo/geosite/"
          head -20 ../geosite_files.txt

      - name: Process ALL geosite JSON files from MetaCubeX
        run: |
          set -e
          MAX_ENTRIES_PER_FILE="${{ env.MAX_ENTRIES_PER_FILE }}"
          REPO_DIR="meta-rules-dat"
          excluded_tlds="cv|dj|dm|im|kg|ki|li|ml|ms|mv|ne|nr|sm|ad|as|bf|bj|bt|cd|cf|ci|ao|bw|ck|ls|mz|vi|zm|bn|bz|cy|et|fj|gi|kh|mm|na|np|pg|sb|sl|vc|mg|ac|af|ag|ai|bi|bs|cg|cm|cu|dz|ga|gd|gl|gm|gs|gy|ht|je|lc|mp|mu|mw|nu|pn|re|rw|sc|sr|st|sx|sy|tf|tj|tl|tt|vg|vu|wf|yt|do|ec|eg|gh|hn|jm|kw|lb|mt|om|py|tr|ae|al|am|at|bg|ch|id|cn|ve|uk|za|zw|ar|au|bd|br|il|ke|nz|th|tz|de|es|fr|gr|hr|hu|ie|is|it|ng|pl|ro|rs|sa|ua|jo|uz|tm|az|ba|bh|bo|by|ca|qa|vn|uy|ug|tn|sv|sk|si|sg|ee|sn|cl|pt|pr|pk|ph|pe|pa|no|ni|my|mx|mn|mk|md|ma|ly|lv|lu|lt|lk|la|kz|kr|iq|in|hk|gt|ge|fi|cr|cz|dk"

          while IFS= read -r json_file; do
            [ -n "$json_file" ] || continue
            resource="${json_file%.json}"
            json_path="$REPO_DIR/geo/geosite/$json_file"
            echo "Processing: $resource ($json_file)"

            # Extract domains, suffixes, regex
            domains=$(jq -r '
              .rules[]
              | if (.domain | type == "string") then [.domain]
                elif (.domain | type == "array") then .domain
                else [] end
              | .[]
            ' "$json_path" 2>/dev/null | sort -u || true)

            suffixes=$(jq -r '
              .rules[]
              | if (.domain_suffix | type == "string") then [.domain_suffix]
                elif (.domain_suffix | type == "array") then .domain_suffix
                else [] end
              | .[]
            ' "$json_path" 2>/dev/null | sort -u || true)

            regex_list=$(jq -r '
              .rules[]
              | if (.domain_regex | type == "string") then [.domain_regex]
                elif (.domain_regex | type == "array") then .domain_regex
                else [] end
              | .[]
            ' "$json_path" 2>/dev/null | sort -u || true)

            # Filter TLDs
            filtered_domains=$(echo "$domains" | grep -Ev "\.($excluded_tlds)$" | grep -v '^$' || true)
            filtered_suffixes=$(echo "$suffixes" | grep -Ev "\.($excluded_tlds)$" | grep -v '^$' || true)
            filtered_regex_list=$(echo "$regex_list" | grep -v '^$' || true)

            # Build entries
            all_entries=()
            [[ -n "$filtered_suffixes" ]] && while IFS= read -r s; do all_entries+=("suffix:$s"); done <<< "$filtered_suffixes"
            [[ -n "$filtered_domains" ]] && while IFS= read -r d; do all_entries+=("domain:$d"); done <<< "$filtered_domains"
            [[ -n "$filtered_regex_list" ]] && while IFS= read -r r; do
              escaped=$(echo "$r" | sed -E 's/\\/\\\\\\\\/g; s/\$/\\$/g; s/"/\\"/g; s/ /\\_/g; s/\?/\\?/g')
              all_entries+=("regex:$escaped")
            done <<< "$filtered_regex_list"

            entry_count=${#all_entries[@]}
            [[ $entry_count -eq 0 ]] && { echo "No entries for $resource, skipping..."; continue; }

            # Write to .rsc (single or split)
            if [ $entry_count -le $MAX_ENTRIES_PER_FILE ]; then
              output="for_scripts/${resource}.rsc"
              {
                echo ":global AddressList"
                echo ":global ForwardTo"
                echo "/ip dns static"
                for e in "${all_entries[@]}"; do
                  type=${e%%:*}
                  value=${e#*:}
                  case "$type" in
                    domain) echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" type=FWD name=\"$value\" }" ;;
                    suffix) echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" match-subdomain=yes type=FWD name=\"$value\" }" ;;
                    regex)  echo ":if ([:len [find regexp=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" type=FWD regexp=\"$value\" }" ;;
                  esac
                done
              } > "$output"
            else
              part=1
              idx=0
              while [ $idx -lt $entry_count ]; do
                output="for_scripts/${resource}_part${part}.rsc"
                {
                  echo ":global AddressList"
                  echo ":global ForwardTo"
                  echo "/ip dns static"
                  for ((i=0; i<MAX_ENTRIES_PER_FILE && idx<entry_count; i++, idx++)); do
                    e=${all_entries[$idx]}
                    type=${e%%:*}
                    value=${e#*:}
                    case "$type" in
                      domain) echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" type=FWD name=\"$value\" }" ;;
                      suffix) echo ":if ([:len [find name=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" match-subdomain=yes type=FWD name=\"$value\" }" ;;
                      regex)  echo ":if ([:len [find regexp=\"$value\"]] = 0) do={ add address-list=\$AddressList forward-to=\$ForwardTo comment=\"dnsfwd:auto:$resource\" type=FWD regexp=\"$value\" }" ;;
                    esac
                  done
                } > "$output"
                part=$((part + 1))
              done
            fi
            echo "Generated $entry_count entries â†’ $resource"
          done < geosite_files.txt

      - name: Validate outputs and write summary
        run: |
          set -eu
          if ! find for_scripts -maxdepth 1 -name '*.rsc' -type f -print -quit | grep -q .; then
            echo "No .rsc files generated in for_scripts; failing to avoid empty commit."
            exit 1
          fi

          rsc_count=$(find for_scripts -maxdepth 1 -name '*.rsc' -type f | wc -l | tr -d ' ')
          rules_count=$(
            { find for_scripts -maxdepth 1 -name '*.rsc' -type f -print0 | xargs -0 grep -h '^:if ' || true; } | wc -l | tr -d ' '
          )
          top_10=$(find for_scripts -maxdepth 1 -name '*.rsc' -type f -print0 | xargs -0 du -h | sort -h | tail -10)

          {
            echo "### for_scripts generation summary"
            echo
            echo "- .rsc files: $rsc_count"
            echo "- rules (:if): $rules_count"
            echo
            echo "Top-10 largest .rsc files:"
            echo '```'
            echo "$top_10"
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Generate for_scripts index files
        run: |
          set -eu
          timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          mapfile -d '' files < <(find for_scripts -maxdepth 1 -name '*.rsc' -type f -print0 | sort -z)
          count=${#files[@]}

          {
            echo "# for_scripts index"
            echo
            echo "Generated at (UTC): $timestamp"
            echo
            echo "Total files: $count"
            echo
            echo "Files:"
            for file in "${files[@]}"; do
              name=$(basename "$file")
              echo "- [$name]($name)"
            done
          } > for_scripts/index.md

          {
            echo "{"
            echo "  \"generated_at\": \"$timestamp\","
            echo "  \"count\": $count,"
            echo "  \"files\": ["
            first=1
            for file in "${files[@]}"; do
              name=$(basename "$file")
              bytes=$(stat -c %s "$file")
              if [ $first -eq 0 ]; then
                echo ","
              fi
              echo "    { \"name\": \"$name\", \"bytes\": $bytes }"
              first=0
            done
            echo
            echo "  ]"
            echo "}"
          } > for_scripts/index.json

      - name: Commit and push
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git pull --rebase origin main
          git add for_scripts
          git commit -m "Auto-update: iplist + ALL MetaCubeX geosite (local clone)" || exit 0
          git push
